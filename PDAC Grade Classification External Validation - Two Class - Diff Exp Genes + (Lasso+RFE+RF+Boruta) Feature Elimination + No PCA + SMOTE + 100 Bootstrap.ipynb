{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd15729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO: Find the best n transcripts by April 29th\\n    - do feature selection with: 1) Lasso 2) RFE 3) Boruta 4) RF 5) Any Combo - done\\n    - run LassoLR, RF, Pamr, XgBoost, Boruta over all diff expressed genes - done\\n    - store running array of sorted descending RF variable importance if AUC > 0.7 - done!\\n    - store running array of sorted descending LassoLR coefficient size if AUC > 0.7 - done!\\n    - store running array of sorted descending XgBoost coefficient size if AUC > 0.7 - done!\\n    - store running array of sorted descending Boruta coefficient size if AUC > 0.7 - done!\\n    - find the intersection of the top n genes that gives x important genes  - done!\\n    - rerun the best model on ALL the data with only the top x important genes - done!\\n\\nTODO Figures:\\n\\n1) Top 12 best overlapping forward pass -> add PFS and OS of class I vs class II in the test set\\n2) Top 12 best overlapping -> retrain on the full dataset with the best params and SAVE - done!\\n3) SAVED Top 12 overlapping -> test on the new test dataset with survival \\n    (unfortunately first validation set only had one Grade I tumor)\\n    (try with validation set #2 as well!)\\n4) External validation bootstrapped F1 scores bar plot\\n5) Summary slides of methods for audience\\n6) Optional: Kaplan-Meier Curves on train/test labels - done!\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### USING ALL DIFF EXP (1335)-(Lasso and RFE 100 overlap feature elimination)+No PCA+SMOTE+50 REPEATS = 12 FEATURES\n",
    "\n",
    "'''\n",
    "TODO: Find the best n transcripts by April 29th\n",
    "    - do feature selection with: 1) Lasso 2) RFE 3) Boruta 4) RF 5) Any Combo - done\n",
    "    - run LassoLR, RF, Pamr, XgBoost, Boruta over all diff expressed genes - done\n",
    "    - store running array of sorted descending RF variable importance if AUC > 0.7 - done!\n",
    "    - store running array of sorted descending LassoLR coefficient size if AUC > 0.7 - done!\n",
    "    - store running array of sorted descending XgBoost coefficient size if AUC > 0.7 - done!\n",
    "    - store running array of sorted descending Boruta coefficient size if AUC > 0.7 - done!\n",
    "    - find the intersection of the top n genes that gives x important genes  - done!\n",
    "    - rerun the best model on ALL the data with only the top x important genes - done!\n",
    "\n",
    "TODO Figures:\n",
    "\n",
    "1) Top 12 best overlapping forward pass -> add PFS and OS of class I vs class II in the test set\n",
    "2) Top 12 best overlapping -> retrain on the full dataset with the best params and SAVE - done!\n",
    "3) SAVED Top 12 overlapping -> test on the new test dataset with survival \n",
    "    (unfortunately first validation set only had one Grade I tumor)\n",
    "    (try with validation set #2 as well!)\n",
    "4) External validation bootstrapped F1 scores bar plot\n",
    "5) Summary slides of methods for audience\n",
    "6) Optional: Kaplan-Meier Curves on train/test labels - done!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd13d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Revisit normalizing transcripts based on tissue type\n",
    "# DONE?: Generate gene score assay (probability of a grade from logistic regression, weights from RF)\n",
    "# DONE?: exclude M1\n",
    "# DONE: Exclude G4 and Gx\n",
    "# DONE: try with differentially expressed genes only - doesn't help improve results\n",
    "\n",
    "# three_class = True; two_class = False # (Grade I, Grade II, Grade III/IV)\n",
    "two_class = True; three_class = False #(Grade I/II, Grade III/IV)\n",
    "\n",
    "# Toggle to use_differentially_expressed_genes\n",
    "use_differentially_expressed_genes=True; first_n_diff_exp_genes = None # Use all differentially expressed genes\n",
    "# use_differentially_expressed_genes=True; first_n_diff_exp_genes = 500 # Use top 500 differentially expressed genes\n",
    "# use_differentially_expressed_genes=False # use all 19904 genes\n",
    "\n",
    "# Toggle to discretize z-scores into 3 or 5 groups (or don't discretize at all)\n",
    "discretize_z_three = True; discretize_z_five = False\n",
    "# discretize_z_five = True; discretize_z_three = False\n",
    "# discretize_z_five = False; discretize_z_three = False\n",
    "\n",
    "# Toggle to use various feature reduction methods (comment out/in as many as needed)\n",
    "use_lasso=True\n",
    "# use_lasso=False\n",
    "use_rfe=True; number_of_rfe_genes_to_keep = 100\n",
    "# use_rfe=False\n",
    "use_rf=True\n",
    "# use_rf=False\n",
    "use_boruta=True\n",
    "# use_boruta=False\n",
    "\n",
    "# Toggle to use PCA to reduce dimensionality of data before passing into the algorithm\n",
    "# use_PCA=True; number_of_PCA_components = 10 # number_of_PCA_components must be less than first_n_diff_exp_genes\n",
    "use_PCA=False\n",
    "\n",
    "# We are using a bootstrap nested repeated k-fold cross validation procedure for training and testing\n",
    "# Decide the number of bootstraps to bootstrap the CV\n",
    "num_bootstrap_iterations = 100\n",
    "\n",
    "# Decide the number of repeats to run the repeated CV\n",
    "# num_repeats = 50\n",
    "num_repeats = 1\n",
    "\n",
    "# Decide the number of k-splits to run the k-fold CV\n",
    "num_splits = 5\n",
    "\n",
    "# Decide whether to override the training dataset to only use the top 50 most important features out of 500 differentially expressed genes, as chosen by RF\n",
    "use_top_50_most_important_out_of_500 = False; use_top_100_most_important_out_of_500 = False\n",
    "# use_top_50_most_important_out_of_500 = True; use_top_100_most_important_out_of_500 = False\n",
    "# use_top_100_most_important_out_of_500 = True; use_top_50_most_important_out_of_500 = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303d8bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chat GPT-4 Initial Prompt\n",
    "Please write code according to the methods described below:\n",
    "\n",
    "l2-regularized multinomial Logistic Regression (LR) on the normalized and transformed data using 5-fold nested cross validation - more specifically: Logistic regression with an l2 penalty, trained via stochastic gradient descent. The logistic regression model is a single layer neural network with a softmax activation on the output. The hyperparameter optimized was the l2 penalty, logarithmically spaced between 10−6 and 103 in ten steps. The model was implemented in pytorch [56]. \n",
    "\n",
    "Also, use these Logistic Regression Hyperparameters.\n",
    "• Weights were initialized randomly according to the standard (Xavier) Glorot\n",
    "normal [3] prescription.\n",
    "• The learning rate was reduced from init. LR by a factor of LR gamma every LR\n",
    "step epochs.\n",
    "• The l2-coeff value is selected by cross-validation over the range 10−6 to 103\n",
    "in logarithmic steps of 10.\n",
    "• All SGD used ADAM [1] with parameters (0.5, 0.999). epochs = 500, batch size =  floor(num. samples / 5),  LR = 0.00001\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(42)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1f50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define models\n",
    "'''\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if three_class:\n",
    "            return nn.functional.softmax(self.linear(x), dim=1)\n",
    "        elif two_class:\n",
    "            return self.linear(x)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def glorot_normal_initialization(layer):\n",
    "    if type(layer) == nn.Linear:\n",
    "        nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        if three_class:\n",
    "            outputs = model(batch_x)\n",
    "        elif two_class:\n",
    "            outputs = model(batch_x).flatten()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            if three_class:\n",
    "                outputs = model(batch_x)\n",
    "            elif two_class:\n",
    "                outputs = model(batch_x).flatten()\n",
    "            if three_class:\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            elif two_class:\n",
    "                predicted = (outputs > 0.5).long()\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732fbf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differentially expressed genes: 1527\n",
      "Total number of genes in transcript dataset: 19904\n",
      "Total number of differentially expressed genes in transcript dataset: 1335\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load in the data\n",
    "'''\n",
    "\n",
    "# Dataset 1: RNA transcripts centered and converted to Z-scores relative to all samples\n",
    "df_X = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem_zscores_ref_all_samples.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "# Dataset 2: RNA transcripts centered and converted to Z-scores relative to diploid samples\n",
    "# df_X = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem_zscores_ref_diploid_samples.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "# Dataset 3: Protein expression levels centered and converted to Z-scores relative to all samples\n",
    "# df_X = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_rppa_zscores.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "# Differentially Expressed Genes Dataset:\n",
    "df_X_diff_G1    = pd.read_csv('RE_ Molecular profiling Project/TCGA 2018 PDAC N_171 - DE genes enriched in G1 (vs G2-3).tsv', sep='\\t')\n",
    "df_X_diff_G2_G3 = pd.read_csv('RE_ Molecular profiling Project/TCGA 2018 PDAC N_171 - DE genes enriched in G2-3 (vs G1).tsv', sep='\\t')\n",
    "\n",
    "if first_n_diff_exp_genes:\n",
    "    df_X_diff_G1 = df_X_diff_G1.head(round(first_n_diff_exp_genes/2)).copy()\n",
    "    df_X_diff_G2_G3 = df_X_diff_G2_G3.head(round(first_n_diff_exp_genes/2)).copy()\n",
    "\n",
    "differentially_expressed_gene_set = set(df_X_diff_G1['Gene']).union(set(df_X_diff_G2_G3['Gene'])) # Using genes differentally expressed in G1 OR G2/3\n",
    "# differentially_expressed_gene_set = set(df_X_diff_G1['Gene']).union(set(df_X_diff_G1['Gene'])) # Only using genes differentally expressed in G1 vs G2/3\n",
    "# differentially_expressed_gene_set = set(df_X_diff_G2_G3['Gene']).union(set(df_X_diff_G2_G3['Gene'])) # Only using genes differentally expressed in G2/3 vs G1\n",
    "\n",
    "# Dataset Labels 1: Patients labeled by tumor GRADE\n",
    "df_y = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_sample.txt\", sep='\\t', index_col=[0, 1])\n",
    "# print(df_y['Neoplasm Histologic Grade'].unique())\n",
    "\n",
    "# Dataset Labels 2: Patients labeled by tumor STAGE # Deprecated\n",
    "# df_y = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_patient.txt\", sep='\\t', index_col=[0, 1])\n",
    "# df_y['Neoplasm Disease Stage American Joint Committee on Cancer Code'].unique()\n",
    "# Unique values include 'STAGE I','STAGE IA', 'STAGE IB', 'STAGE IIA', 'STAGE IIB', 'STAGE III','STAGE IV'\n",
    "\n",
    "def generate_trinary_class_label(grade):\n",
    "    \"\"\"\n",
    "    To get three classes from the provided data\n",
    "    'G1' will be kept as 'G1'\n",
    "    'G2' will be kept as 'G2'\n",
    "    'G3' will be kept as 'G3'\n",
    "    'G4' and 'GX' will be excluded\n",
    "    \"\"\"\n",
    "    if grade in ['G1']:\n",
    "        return 0 # 'G1'\n",
    "    elif grade in ['G2']:\n",
    "        return 1 # 'G2'\n",
    "    elif grade in ['G3']:\n",
    "        return 2 # 'G3'\n",
    "    elif grade in ['G4', 'GX']:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def generate_binary_class_label(grade):\n",
    "    \"\"\"\n",
    "    To get two classes from the provided data\n",
    "    'G1' will be kept as 'G1'\n",
    "    'G2' will be changed to 'G2/3'\n",
    "    'G3' will be changed to 'G2/3'\n",
    "    'G4' and 'GX' will be excluded\n",
    "    \"\"\"\n",
    "    if grade in ['G1']:\n",
    "        return 0 # 'G1'\n",
    "    elif grade in ['G2']:\n",
    "        return 1 # 'G2/3'\n",
    "    elif grade in ['G3']:\n",
    "        return 1 # 'G2/3'\n",
    "    elif grade in ['G4', 'GX']:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "if three_class:\n",
    "    # Update the class labels according to the generate_trinary_class_label function\n",
    "    df_y['Neoplasm Histologic Grade'] = df_y['Neoplasm Histologic Grade'].apply(generate_trinary_class_label)\n",
    "\n",
    "if two_class:\n",
    "    # OR\n",
    "    # Update the class labels according to the generate_binary_class_label function\n",
    "    df_y['Neoplasm Histologic Grade'] = df_y['Neoplasm Histologic Grade'].apply(generate_binary_class_label)\n",
    "\n",
    "\n",
    "# Remove patients that do not have a tumor grade assigned or are grade 4\n",
    "df_y.dropna(subset=['Neoplasm Histologic Grade'], inplace=True)\n",
    "\n",
    "# Next, transpose the MRNA seq scores so that each row corresponds to a patient and each column corresponds to a feature or mRNA expression level\n",
    "df_X = df_X.transpose()\n",
    "\n",
    "# Remove all columns (features) with any NaN values\n",
    "df_X = df_X.dropna(axis=1)\n",
    "\n",
    "# Print the size of the gene set\n",
    "print(f'Number of differentially expressed genes: {len(differentially_expressed_gene_set)}')\n",
    "# Print the size of the filtered dataframe\n",
    "print(f'Total number of genes in transcript dataset: {df_X.shape[1]}')\n",
    "if use_differentially_expressed_genes:\n",
    "    # Drop columns in df_X that are not in the differentially expressed gene set\n",
    "    df_X = df_X.drop(columns=[col for col in df_X.columns if col[0] not in differentially_expressed_gene_set])\n",
    "print(f'Total number of differentially expressed genes in transcript dataset: {df_X.shape[1]}')\n",
    "\n",
    "# Keep only patient IDs with both mRNA sequence data AND tumor grade values\n",
    "X = df_X\n",
    "y = df_y['Neoplasm Histologic Grade']\n",
    "\n",
    "# Find common patient IDs\n",
    "X.index = X.index.str.replace('-01', '')\n",
    "common_ids = list(set(X.index) & set(y.index.get_level_values('#Patient Identifier')))\n",
    "\n",
    "# Filter X and y to contain only common patient IDs\n",
    "X_common = X.loc[common_ids]\n",
    "y_common = y.loc[y.index.get_level_values('#Patient Identifier').isin(common_ids)]\n",
    "\n",
    "# Sort X and y by patient ID\n",
    "X_common.sort_index(inplace=True)\n",
    "y_common.sort_index(inplace=True)\n",
    "\n",
    "# print(X_common.head())\n",
    "# print(y_common.head())\n",
    "\n",
    "# Convert X and y to arrays\n",
    "X = X_common.values\n",
    "y = y_common.values\n",
    "\n",
    "if discretize_z_three:\n",
    "    # Ternarize X (ternarized normalization discretized the Z-scores into down-regulated (Z<−2), normal (−2<Z<2), or up-regulated (Z>2) categories)\n",
    "    X = np.where(X < -2, -1, np.where(X > 2, 1, 0))\n",
    "\n",
    "if discretize_z_five:\n",
    "    # Discretize the Z-scores into \n",
    "    # Very downregulated: Z <= -2 (assigned as -2)\n",
    "    # Downregulated: -2 < Z <= -1 (assigned as -1)\n",
    "    # Normal: -1 < Z <= 1 (assigned as 0)\n",
    "    # Upregulated: 1 < Z <= 2 (assigned as 1)\n",
    "    # Very upregulated: Z > 2 (assigned as 2)\n",
    "    X = np.where(X <= -2, -2, np.where(X <= -1, -1, np.where(X <= 1, 0, np.where(X <= 2, 1, 2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7077e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:biothings.client:querying 1-4...\n",
      "INFO:biothings.client:done.\n",
      "INFO:biothings.client:Finished.\n",
      "WARNING:biothings.client:1 input query terms found no hit:\t['ENSG00000274890']\n",
      "INFO:biothings.client:Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DDX11L1', None)\n",
      "('MIR1302-2HG', None)\n",
      "Gene not found: ENSG00000274890\n",
      "('WASH7P', None)\n"
     ]
    }
   ],
   "source": [
    "import mygene\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "ensembl_gene_ids = ['ENSG00000223972', 'ENSG00000243485', 'ENSG00000274890', 'ENSG00000227232']  # replace with your list of Ensembl IDs\n",
    "result = mg.querymany(ensembl_gene_ids, scopes='ensembl.gene', fields='symbol,entrezgene', species='human')\n",
    "\n",
    "# The result is a list of dictionaries, where each dictionary contains information for a gene.\n",
    "# Print the gene symbol and Entrez ID for each gene.\n",
    "for gene_info in result:\n",
    "    if 'notfound' not in gene_info:\n",
    "        print((gene_info['symbol'], gene_info.get('entrezgene')))\n",
    "    else:\n",
    "        print('Gene not found:', gene_info['query'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4dabd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yr/jxtcsvsn719b08f9j5dmbfsr0000gn/T/ipykernel_1128/132053063.py:1: DtypeWarning: Columns (4,14,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('icgc-dataset-1689191752301/exp_seq.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('icgc-dataset-1689191752301/exp_seq.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d38b87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icgc_donor_id</th>\n",
       "      <th>project_code</th>\n",
       "      <th>icgc_specimen_id</th>\n",
       "      <th>icgc_sample_id</th>\n",
       "      <th>submitted_sample_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>gene_model</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>normalized_read_count</th>\n",
       "      <th>raw_read_count</th>\n",
       "      <th>...</th>\n",
       "      <th>platform</th>\n",
       "      <th>total_read_count</th>\n",
       "      <th>experimental_protocol</th>\n",
       "      <th>alignment_algorithm</th>\n",
       "      <th>normalization_algorithm</th>\n",
       "      <th>other_analysis_algorithm</th>\n",
       "      <th>sequencing_strategy</th>\n",
       "      <th>raw_data_repository</th>\n",
       "      <th>raw_data_accession</th>\n",
       "      <th>reference_sample_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DO35083</td>\n",
       "      <td>PACA-CA</td>\n",
       "      <td>SP125746</td>\n",
       "      <td>SA533585</td>\n",
       "      <td>PCSI_0103_Pa_P_526</td>\n",
       "      <td>PACA_CA-WTS</td>\n",
       "      <td>Ensembl</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>0.264808</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Illumina HiSeq</td>\n",
       "      <td>7030698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>star 2-pass https://github.com/alexdobin/STAR</td>\n",
       "      <td>Cufflinks http://cufflinks.cbcb.umd.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>EGA</td>\n",
       "      <td>EGAF00001844283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DO35083</td>\n",
       "      <td>PACA-CA</td>\n",
       "      <td>SP125746</td>\n",
       "      <td>SA533585</td>\n",
       "      <td>PCSI_0103_Pa_P_526</td>\n",
       "      <td>PACA_CA-WTS</td>\n",
       "      <td>Ensembl</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Illumina HiSeq</td>\n",
       "      <td>7030698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>star 2-pass https://github.com/alexdobin/STAR</td>\n",
       "      <td>Cufflinks http://cufflinks.cbcb.umd.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>EGA</td>\n",
       "      <td>EGAF00001844283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DO35083</td>\n",
       "      <td>PACA-CA</td>\n",
       "      <td>SP125746</td>\n",
       "      <td>SA533585</td>\n",
       "      <td>PCSI_0103_Pa_P_526</td>\n",
       "      <td>PACA_CA-WTS</td>\n",
       "      <td>Ensembl</td>\n",
       "      <td>ENSG00000274890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Illumina HiSeq</td>\n",
       "      <td>7030698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>star 2-pass https://github.com/alexdobin/STAR</td>\n",
       "      <td>Cufflinks http://cufflinks.cbcb.umd.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>EGA</td>\n",
       "      <td>EGAF00001844283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DO35083</td>\n",
       "      <td>PACA-CA</td>\n",
       "      <td>SP125746</td>\n",
       "      <td>SA533585</td>\n",
       "      <td>PCSI_0103_Pa_P_526</td>\n",
       "      <td>PACA_CA-WTS</td>\n",
       "      <td>Ensembl</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>62.827200</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>Illumina HiSeq</td>\n",
       "      <td>7030698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>star 2-pass https://github.com/alexdobin/STAR</td>\n",
       "      <td>Cufflinks http://cufflinks.cbcb.umd.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>EGA</td>\n",
       "      <td>EGAF00001844283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DO35083</td>\n",
       "      <td>PACA-CA</td>\n",
       "      <td>SP125746</td>\n",
       "      <td>SA533585</td>\n",
       "      <td>PCSI_0103_Pa_P_526</td>\n",
       "      <td>PACA_CA-WTS</td>\n",
       "      <td>Ensembl</td>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Illumina HiSeq</td>\n",
       "      <td>7030698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>star 2-pass https://github.com/alexdobin/STAR</td>\n",
       "      <td>Cufflinks http://cufflinks.cbcb.umd.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>EGA</td>\n",
       "      <td>EGAF00001844283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  icgc_donor_id project_code icgc_specimen_id icgc_sample_id  \\\n",
       "0       DO35083      PACA-CA         SP125746       SA533585   \n",
       "1       DO35083      PACA-CA         SP125746       SA533585   \n",
       "2       DO35083      PACA-CA         SP125746       SA533585   \n",
       "3       DO35083      PACA-CA         SP125746       SA533585   \n",
       "4       DO35083      PACA-CA         SP125746       SA533585   \n",
       "\n",
       "  submitted_sample_id  analysis_id gene_model          gene_id  \\\n",
       "0  PCSI_0103_Pa_P_526  PACA_CA-WTS    Ensembl  ENSG00000223972   \n",
       "1  PCSI_0103_Pa_P_526  PACA_CA-WTS    Ensembl  ENSG00000243485   \n",
       "2  PCSI_0103_Pa_P_526  PACA_CA-WTS    Ensembl  ENSG00000274890   \n",
       "3  PCSI_0103_Pa_P_526  PACA_CA-WTS    Ensembl  ENSG00000227232   \n",
       "4  PCSI_0103_Pa_P_526  PACA_CA-WTS    Ensembl  ENSG00000278267   \n",
       "\n",
       "   normalized_read_count  raw_read_count  ...        platform  \\\n",
       "0               0.264808               0  ...  Illumina HiSeq   \n",
       "1               0.000000               0  ...  Illumina HiSeq   \n",
       "2               0.000000               0  ...  Illumina HiSeq   \n",
       "3              62.827200              40  ...  Illumina HiSeq   \n",
       "4               0.000000               0  ...  Illumina HiSeq   \n",
       "\n",
       "  total_read_count experimental_protocol  \\\n",
       "0        7030698.0                   NaN   \n",
       "1        7030698.0                   NaN   \n",
       "2        7030698.0                   NaN   \n",
       "3        7030698.0                   NaN   \n",
       "4        7030698.0                   NaN   \n",
       "\n",
       "                             alignment_algorithm  \\\n",
       "0  star 2-pass https://github.com/alexdobin/STAR   \n",
       "1  star 2-pass https://github.com/alexdobin/STAR   \n",
       "2  star 2-pass https://github.com/alexdobin/STAR   \n",
       "3  star 2-pass https://github.com/alexdobin/STAR   \n",
       "4  star 2-pass https://github.com/alexdobin/STAR   \n",
       "\n",
       "                   normalization_algorithm other_analysis_algorithm  \\\n",
       "0  Cufflinks http://cufflinks.cbcb.umd.edu                      NaN   \n",
       "1  Cufflinks http://cufflinks.cbcb.umd.edu                      NaN   \n",
       "2  Cufflinks http://cufflinks.cbcb.umd.edu                      NaN   \n",
       "3  Cufflinks http://cufflinks.cbcb.umd.edu                      NaN   \n",
       "4  Cufflinks http://cufflinks.cbcb.umd.edu                      NaN   \n",
       "\n",
       "  sequencing_strategy raw_data_repository raw_data_accession  \\\n",
       "0             RNA-Seq                 EGA    EGAF00001844283   \n",
       "1             RNA-Seq                 EGA    EGAF00001844283   \n",
       "2             RNA-Seq                 EGA    EGAF00001844283   \n",
       "3             RNA-Seq                 EGA    EGAF00001844283   \n",
       "4             RNA-Seq                 EGA    EGAF00001844283   \n",
       "\n",
       "  reference_sample_type  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea0163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.302543e+06\n",
       "mean     6.756848e+01\n",
       "std      3.410000e+04\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      8.073220e-01\n",
       "max      6.939670e+07\n",
       "Name: normalized_read_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df_test['gene_id'].unique())\n",
    "df_test['normalized_read_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db3da0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumour_grade\n",
       "2 - Moderately differentiated                159\n",
       "3 - Poorly differentiated                     95\n",
       "Moderately differentiated                     87\n",
       "Poorly differentiated                         61\n",
       "Well differentiated                           25\n",
       "X - Cannot be assessed                        17\n",
       "G2                                            12\n",
       "4 - Undifferentiated                          10\n",
       "Undifferentiated                               6\n",
       "G1                                             5\n",
       "G3                                             4\n",
       "1 - Well differentiated                        3\n",
       "Not specified/Unknown                          2\n",
       "Other - Status Post Therapy                    2\n",
       "Poorly differentiated to Undifferentiated      1\n",
       "Moderate to Poor                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('icgc-dataset-1689191752301/specimen.tsv', sep='\\t')\n",
    "df_test['tumour_grade'].value_counts()\n",
    "# 159+95+87+61+12+4\n",
    "'''\n",
    "Exclude:\n",
    "Not specified/Unknown                          \n",
    "Other - Status Post Therapy\n",
    "X - Cannot be assessed  \n",
    "'''\n",
    "\n",
    "'''\n",
    "G1: Well\n",
    "G2: Moderaate\n",
    "G3: Poor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the range of indices\n",
    "# indices = np.arange(X.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# # Split the train and test data and indices\n",
    "# X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "#     X, y, indices, test_size=0.2, stratify=y, random_state=0\n",
    "# )\n",
    "\n",
    "# Get the patient IDs for the samples in X_test\n",
    "# patient_ids_train = X_common.index[train_indices]\n",
    "# patient_ids_test = X_common.index[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print(f'There are {X_train.shape[1]} features in the training data.')\n",
    "\n",
    "if use_lasso or use_rfe or use_rf or use_boruta:\n",
    "    lasso_support_indices = []\n",
    "    rfe_support_indices = []\n",
    "    from boruta import BorutaPy\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Initialize empty lists for Random Forest and Boruta support indices\n",
    "    rf_support_indices = []\n",
    "    boruta_support_indices = []\n",
    "    \n",
    "    # Use Lasso for feature reduction (only use features with non-zero coefficients)\n",
    "    if use_lasso:\n",
    "        lasso = LassoCV(cv=5).fit(X_train, y_train)\n",
    "        coef = lasso.coef_\n",
    "        important_features_indices = np.where(coef != 0)[0]\n",
    "        X_lasso = X_train[:, important_features_indices]\n",
    "        lasso_support_indices = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "        print('\\n')\n",
    "        print(f'Lasso regression selected {X_lasso.shape[1]} important features in the training data.')\n",
    "\n",
    "    # Use Recursive Feature Elimination for feature reduction to a pre-set number of genes\n",
    "    if use_rfe:\n",
    "        model = LinearRegression()\n",
    "        rfe = RFE(model, n_features_to_select=number_of_rfe_genes_to_keep)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        X_rfe = X_train[:, rfe.support_]\n",
    "        rfe_support_indices = np.where(rfe.support_)[0]\n",
    "\n",
    "        print('\\n')\n",
    "        print(f'Recursive feature elimination (RFE) eliminated  all but {X_rfe.shape[1]} important features in the training data.')\n",
    "    \n",
    "    # Use Random Forest for feature reduction (select the n most important genes)\n",
    "    if use_rf:\n",
    "        rf = RandomForestClassifier(n_estimators=1000, random_state=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Get feature importances and calculate the cumulative sum\n",
    "        importances = rf.feature_importances_\n",
    "        cumsum_importances = np.cumsum(np.sort(importances)[::-1])\n",
    "\n",
    "        # Get the indices that would sort the importances array\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Get the indices for the features that make up 50% of the importance\n",
    "        total_rf_feature_importance=0.50\n",
    "        rf_support_indices = sorted_indices[:np.where(cumsum_importances > total_rf_feature_importance)[0][0]]\n",
    "\n",
    "        print(f'\\nRandom Forest selected {len(rf_support_indices)} important features in the training data with total {total_rf_feature_importance*100}% feature importance.')\n",
    "    \n",
    "    # Use Boruta for feature reduction (select the n most important genes)\n",
    "    if use_boruta:\n",
    "        z_score_threshold = 0.9\n",
    "        rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "        boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1, perc=z_score_threshold)   \n",
    "        boruta_selector.fit(X_train, y_train)\n",
    "\n",
    "        boruta_support_indices = np.where(boruta_selector.support_)[0]\n",
    "\n",
    "        print(f'\\nBoruta selected {len(boruta_support_indices)} important features in the training data at {z_score_threshold} z-score threshold difference.')\n",
    "\n",
    "    # Construct a list of arrays with indices of features selected by each method\n",
    "    arrays = [x for x in (rfe_support_indices, lasso_support_indices, rf_support_indices, boruta_support_indices) if len(x) != 0]\n",
    "    \n",
    "    # Compute the common indices from all methods\n",
    "    common_indices = reduce(np.intersect1d, arrays)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(f'After feature reduction, {len(common_indices)} features remain in the training data (overlapping between multiple methods).')\n",
    "\n",
    "    X_train = X_train[:, common_indices]\n",
    "    X_test = X_test[:, common_indices]\n",
    "    print('\\n')\n",
    "    print(f'X_train and X_test now have {X_train.shape[1]} features each from the feature reduction.')\n",
    "\n",
    "# Use PCA to extract relevant features from the dataset\n",
    "if use_PCA:\n",
    "    pca = PCA(n_components=number_of_PCA_components)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "if use_PCA:\n",
    "    print(f'There are {X_train.shape[1]} features in the training data after PCA.')\n",
    "\n",
    "print('\\n')\n",
    "print(f'There are {round(y_train.sum()/len(y_train)*100)}% positive examples of out {len(y_train)} in the training data.')\n",
    "print(f'There are {round(y_test.sum()/len(y_test)*100)}% positive examples of out {len(y_test)} in the test data.')\n",
    "\n",
    "# Save the X-train and y-train varaiables for train dataset surival curves below\n",
    "X_train_no_SMOTE = X_train\n",
    "y_train_no_SMOTE = y_train\n",
    "\n",
    "# Instantiate the SMOTE algorithm and resample the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('\\n')\n",
    "print(f'After SMOTE there are {round(y_train.sum()/len(y_train)*100)}% positive examples in the training data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fb2222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining genes after feature reduction\n",
      "[('BCL11A', 53335), ('C5', 727), ('GAN', 8139), ('HAPLN4', 404037), ('IL31RA', 133396), ('LY6D', 8581), ('NXNL2', 158046), ('OR2C3', 81472), ('PNPLA1', 285848), ('RAD51', 5888), ('RHO', 6010), ('RRAGC', 64121), ('TEX12', 56158), ('VAMP3', 9341)]\n"
     ]
    }
   ],
   "source": [
    "if use_lasso or use_rfe or use_rf or use_boruta:\n",
    "    top_common_genes = [X_common.columns[i] for i in common_indices]\n",
    "    print(f'Remaining genes after feature reduction')\n",
    "    print(top_common_genes)\n",
    "    top_common_genes = [(gene, int(count)) for gene, count in top_common_genes]\n",
    "    with open(f'Best remaining {len(top_common_genes)} genes.json', 'w') as f:\n",
    "        json.dump(top_common_genes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fed51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nNOTE: Logistic Regression with l2 regularization is returning an accuracy of 50%\\nwhich means that it is just guessing. So we will not continue with this model\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "NOTE: Logistic Regression with l2 regularization is returning an accuracy of 50%\n",
    "which means that it is just guessing. So we will not continue with this model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94aaef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "if three_class:\n",
    "    class_labels = ['Grade I', 'Grade II', 'Grade III']\n",
    "elif two_class:\n",
    "    class_labels = ['Grade I', 'Grade II/III']\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix_sum, class_labels):\n",
    "    # Calculate the percentage of each value in the confusion matrix by column\n",
    "    percentage_matrix = conf_matrix_sum / conf_matrix_sum.sum(axis=0, keepdims=True) * 100\n",
    "\n",
    "    # Calculate sensitivity, specificity, and F1 score\n",
    "    sensitivity = np.diag(conf_matrix_sum) / np.sum(conf_matrix_sum, axis=1)\n",
    "    specificity = np.diag(conf_matrix_sum) / np.sum(conf_matrix_sum, axis=0)\n",
    "    f1_scores = 2 * (sensitivity * specificity) / (sensitivity + specificity)\n",
    "\n",
    "    # Create a custom function to display both the count and the percentage in the heatmap\n",
    "    def display_count_percentage(matrix, count_matrix, percentage_matrix):\n",
    "        for y in range(matrix.shape[0]):\n",
    "            for x in range(matrix.shape[1]):\n",
    "                c = count_matrix[y, x]\n",
    "                p = percentage_matrix[y, x]\n",
    "                matrix[y, x] = f'{c}\\n({p:.1f}%)'\n",
    "\n",
    "    # Combine count and percentage in a single matrix\n",
    "    combined_matrix = np.empty(conf_matrix_sum.shape, dtype=object)\n",
    "    display_count_percentage(combined_matrix, conf_matrix_sum, percentage_matrix)\n",
    "\n",
    "    # Plot the heatmap with count and percentage\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(percentage_matrix, annot=combined_matrix, fmt='', cmap='Blues', cbar=False, xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    # Display sensitivity, specificity, and F1 score\n",
    "    for i, label in enumerate(class_labels):\n",
    "        plt.text(len(class_labels) + 0.5, i + 0.5, f'Sensitivity: {sensitivity[i]:.2f}\\nSpecificity: {specificity[i]:.2f}\\nF1 Score: {f1_scores[i]:.2f}',\n",
    "                 va='center', ha='left', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping...: 100%|███████████████████████████| 5/5 [00:03<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping...:  40%|██████████▊                | 2/5 [01:25<02:07, 42.59s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from collections import defaultdict\n",
    "\n",
    "def bootstrap_nested_repeated_cv(model, params_ranges, X, y, X_test, y_test, num_bootstrap_iterations, num_repeats, num_splits):\n",
    "    param_scores = defaultdict(list)\n",
    "    nested_cv_scores = []\n",
    "    nested_conf_matrix = []\n",
    "    nested_f1_score = []\n",
    "    nested_importances = np.zeros((1, X.shape[1]))\n",
    "    bootstrap_accuracy = []\n",
    "    bootstrap_conf_matrix = []\n",
    "    bootstrap_f1_score = []\n",
    "    random_seed = 0\n",
    "\n",
    "    # Bootstrap iterations\n",
    "    for i in tqdm(range(num_bootstrap_iterations),'Bootstrapping...'):\n",
    "        # Resample the data with replacement to form a new dataset\n",
    "        X_resampled, y_resampled = resample(X, y, random_state=i)\n",
    "        best_score = 0\n",
    "        best_params = None\n",
    "        best_model = None\n",
    "        \n",
    "        # Nested cross-validation\n",
    "        for param_set in params_ranges:\n",
    "            inner_scores = []\n",
    "            for i in range(num_repeats):\n",
    "                # Update the kf with the current random_seed\n",
    "                kf = KFold(n_splits=num_splits, shuffle=True, random_state=random_seed)\n",
    "                # Update the random seed so that there is a new split on every run\n",
    "                random_seed += 1\n",
    "                for train_index, test_index in kf.split(X_resampled):\n",
    "                    X_train, X_val = X_resampled[train_index], X_resampled[test_index]\n",
    "                    y_train, y_val = y_resampled[train_index], y_resampled[test_index]\n",
    "\n",
    "                    model.set_params(**param_set)\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                    score = model.score(X_val, y_val)\n",
    "                    nested_cv_scores.append(score)\n",
    "\n",
    "                    if hasattr(model, 'feature_importances_'):\n",
    "                        importances = model.feature_importances_\n",
    "                        nested_importances += importances\n",
    "\n",
    "                    y_pred = model.predict(X_val)\n",
    "\n",
    "                    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "                    nested_conf_matrix.append(conf_matrix)\n",
    "\n",
    "                    # Compute F1-score\n",
    "                    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "                    nested_f1_score.append(f1)\n",
    "\n",
    "                    inner_scores.append(f1)\n",
    "\n",
    "            # Keep track of the best model, params and score within each bootstrap iteration\n",
    "            mean_score = np.mean(inner_scores)\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_params = param_set\n",
    "                best_model = model\n",
    "                \n",
    "            param_scores[str(param_set)].append(mean_score)\n",
    "\n",
    "        # At the end of each bootstrap iteration, evaluate the best model on the test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "        f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        bootstrap_accuracy.append(accuracy_test)\n",
    "        bootstrap_conf_matrix.append(conf_matrix_test)\n",
    "        bootstrap_f1_score.append(f1_test)\n",
    "\n",
    "    # Get the best parameter set based on average score across all bootstrap iterations\n",
    "    best_params_overall = max(param_scores, key=lambda k: np.mean(param_scores[k]))\n",
    "    best_score_overall = np.mean(param_scores[best_params_overall])\n",
    "\n",
    "    # Train the final model with the best parameters on the entire dataset\n",
    "    best_model_overall = model.set_params(**eval(best_params_overall))\n",
    "    best_model_overall.fit(np.concatenate((X, X_test)), np.concatenate((y, y_test)))\n",
    "\n",
    "    return best_model_overall, best_params_overall, best_score_overall, nested_cv_scores, nested_conf_matrix, nested_f1_score, nested_importances, bootstrap_accuracy, bootstrap_conf_matrix, bootstrap_f1_score\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "print('K-Nearest Neighbors')\n",
    "knn_params_ranges = [{'n_neighbors': n, 'weights': w} for n in [1, 3, 5, 7, 9] for w in ['uniform', 'distance']]\n",
    "(\n",
    "    best_knn_model_overall, \n",
    "    best_knn_params_overall, \n",
    "    best_knn_score_overall, \n",
    "    knn_nested_cv_scores, \n",
    "    knn_nested_conf_matrix, \n",
    "    knn_nested_f1_score, _, \n",
    "    knn_bootstrap_accuracy, \n",
    "    knn_bootstrap_conf_matrix, \n",
    "    knn_bootstrap_f1_score\n",
    ") = bootstrap_nested_repeated_cv(\n",
    "    KNeighborsClassifier(), \n",
    "    knn_params_ranges, \n",
    "    X_train, y_train, \n",
    "    X_test, y_test, \n",
    "    num_bootstrap_iterations, \n",
    "    num_repeats, \n",
    "    num_splits\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "print('Random Forest')\n",
    "rf_params_ranges = [{'n_estimators': n, 'max_depth': d} for n in [10, 50, 100, 200, 500] for d in [3, 6, 10, 15]]\n",
    "(\n",
    "    best_rf_model_overall, \n",
    "    best_rf_params_overall, \n",
    "    best_rf_score_overall, \n",
    "    rf_nested_cv_scores, \n",
    "    rf_nested_conf_matrix, \n",
    "    rf_nested_f1_score, \n",
    "    rf_nested_importances, \n",
    "    rf_bootstrap_accuracy, \n",
    "    rf_bootstrap_conf_matrix, \n",
    "    rf_bootstrap_f1_score\n",
    ") = bootstrap_nested_repeated_cv(\n",
    "    RandomForestClassifier(), \n",
    "    rf_params_ranges, \n",
    "    X_train, y_train, \n",
    "    X_test, y_test, \n",
    "    num_bootstrap_iterations, \n",
    "    num_repeats, \n",
    "    num_splits\n",
    ")\n",
    "\n",
    "# SVM\n",
    "print('SVM')\n",
    "# k in ['linear', 'rbf', 'sigmoid']\n",
    "svm_params_ranges = [{'kernel': k, 'C': c, 'gamma': g} for k in ['linear'] for c in np.logspace(-3, 6, 5) for g in np.logspace(-3, 6, 5)]\n",
    "(\n",
    "    best_svm_model_overall, \n",
    "    best_svm_params_overall, \n",
    "    best_svm_score_overall, \n",
    "    svm_nested_cv_scores, \n",
    "    svm_nested_conf_matrix, \n",
    "    svm_nested_f1_score, _, \n",
    "    svm_bootstrap_accuracy, \n",
    "    svm_bootstrap_conf_matrix, \n",
    "    svm_bootstrap_f1_score\n",
    ") = bootstrap_nested_repeated_cv(\n",
    "    svm.SVC(max_iter=1000), \n",
    "    svm_params_ranges, \n",
    "    X_train, y_train, \n",
    "    X_test, y_test, \n",
    "    num_bootstrap_iterations, \n",
    "    num_repeats, \n",
    "    num_splits\n",
    ")\n",
    "\n",
    "print(\"Best KNN params:\", best_knn_params_overall, \"Best CV score:\", best_knn_score_overall)\n",
    "print(\"Best RF params:\", best_rf_params_overall, \"Best CV score:\", best_rf_score_overall)\n",
    "print(\"Best SVM params:\", best_svm_params, \"Best CV score:\", best_svm_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best KNN params:\", best_knn_params_overall, \"Best CV score:\", best_knn_score_overall)\n",
    "print(\"Best RF params:\", best_rf_params_overall, \"Best CV score:\", best_rf_score_overall)\n",
    "print(\"Best SVM params:\", best_svm_params_overall, \"Best CV score:\", best_svm_score_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Get a list of genes sorted by feature importance\n",
    "# '''\n",
    "# num_most_important_features = 50\n",
    "# indices_of_top_n_highest_rf_importances = np.argsort(nested_importances[0])[-num_most_important_features:][::-1]\n",
    "\n",
    "# # get the corresponding Hugo_Symbol and Entrez_Gene_Id for each index\n",
    "# top_n_genes = [X_common.columns[i] for i in indices_of_top_n_highest_rf_importances]\n",
    "# sorted_feature_importances = np.sort(nested_importances[0], kind='quicksort', order=None)[::-1][:num_most_important_features]\n",
    "\n",
    "# print('top n genes with feature_importances')\n",
    "# top_n_genes_with_feature_importances = [{'Gene ID':(gene[0],int(gene[1])), 'Importance':round(fi,2)} for gene, fi in zip(top_n_genes, sorted_feature_importances)]\n",
    "# print(top_n_genes_with_feature_importances)\n",
    "\n",
    "# total_importance_captured = sum(sorted_feature_importances)/sum(nested_importances[0])\n",
    "# print(f'Total Importance Captured is {100*total_importance_captured:.2f}%')\n",
    "\n",
    "# with open(f'Top {num_most_important_features} genes with importance.json', 'w') as f:\n",
    "#     json.dump(top_n_genes_with_feature_importances, f)\n",
    "\n",
    "# # Visualize nested cross-validation results\n",
    "# nested_cv_scores = knn_nested_cv_scores + rf_nested_cv_scores + svm_nested_cv_scores\n",
    "# #Create a running average\n",
    "# nested_cv_scores = [sum(nested_cv_scores[:i+1]) / (i+1) for i in range(len(nested_cv_scores))]\n",
    "# plt.plot(range(1, len(nested_cv_scores) + 1), nested_cv_scores, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Nested Cross-Validation Running Average Accuracy')\n",
    "# plt.show()\n",
    "\n",
    "# # Visualize nested cross-validation results\n",
    "# nested_conf_matrix = knn_nested_conf_matrix + rf_nested_conf_matrix + svm_nested_conf_matrix\n",
    "# #Create a running average\n",
    "# # nested_conf_matrix = [sum(nested_conf_matrix[:i+1]) / (i+1) for i in range(len(nested_conf_matrix))]\n",
    "# # Plot the confusion matrix\n",
    "# plot_confusion_matrix(sum(nested_conf_matrix),class_labels)\n",
    "\n",
    "# # Visualize nested cross-validation results\n",
    "# nested_f1_score = knn_nested_f1_score + rf_nested_f1_score + svm_nested_f1_score\n",
    "# #Create a running average\n",
    "# nested_f1_score = [sum(nested_f1_score[:i+1]) / (i+1) for i in range(len(nested_f1_score))]\n",
    "# plt.plot(range(1, len(nested_f1_score) + 1), nested_f1_score, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Nested Cross-Validation Running Average F1-Score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CI\n",
    "\n",
    "def compute_CI(array_of_values):\n",
    "    # Compute sample statistics\n",
    "    mean = np.mean(array_of_values)\n",
    "    std_dev = np.std(array_of_values, ddof=1)  # ddof=1 computes sample standard deviation\n",
    "    n = len(array_of_values)\n",
    "\n",
    "    # Compute the standard error and the 95% Confidence Interval\n",
    "    se = std_dev / np.sqrt(n)\n",
    "    ci = stats.t.interval(confidence=0.95, df=n-1, loc=mean, scale=se)\n",
    "\n",
    "    print(f\"The 95% Confidence Interval is {ci}\")\n",
    "    return ci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ecf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(rf_nested_f1_score, bins=10, kde=True, color='skyblue', label='Random Forest')\n",
    "sns.histplot(knn_nested_f1_score, bins=10, kde=True, color='red', label='K-Nearest Neighbors')\n",
    "sns.histplot(svm_nested_f1_score, bins=10, kde=True, color='green', label='Support Vector Machine')\n",
    "\n",
    "# Set the title and labels with larger font\n",
    "plt.title(\"Validation Set F1-Scores for Bootstrapped Nested Repeated K-Fold Cross-Validation\", fontsize=20, pad=20)\n",
    "plt.xlabel(\"F1-Scores\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot with sufficient space for the title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f02a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_CI(rf_nested_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c42cb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# knn_cv_scores = [sum(knn_nested_cv_scores[:i+1]) / (i+1) for i in range(len(knn_nested_cv_scores))]\n",
    "# rf_cv_scores = [sum(rf_nested_cv_scores[:i+1]) / (i+1) for i in range(len(rf_nested_cv_scores))]\n",
    "# svm_cv_scores = [sum(svm_nested_cv_scores[:i+1]) / (i+1) for i in range(len(svm_nested_cv_scores))]\n",
    "\n",
    "# plt.plot(range(1, len(knn_cv_scores) + 1), knn_cv_scores, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('KNN Nested Cross-Validation Running Average Results')\n",
    "# plt.show()\n",
    "# knn_f1_score = [sum(knn_nested_f1_score[:i+1]) / (i+1) for i in range(len(knn_nested_f1_score))]\n",
    "# plt.plot(range(1, len(knn_f1_score) + 1), knn_f1_score, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('KNN Nested Cross-Validation Running Average F1-Score')\n",
    "# plt.show()\n",
    "# plot_confusion_matrix(sum(knn_nested_conf_matrix),class_labels)\n",
    "\n",
    "# plt.plot(range(1, len(rf_cv_scores) + 1), rf_cv_scores, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('RF Nested Cross-Validation Running Average Results')\n",
    "# plt.show()\n",
    "# rf_f1_score = [sum(rf_nested_f1_score[:i+1]) / (i+1) for i in range(len(rf_nested_f1_score))]\n",
    "# plt.plot(range(1, len(rf_f1_score) + 1), rf_f1_score, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('RF Nested Cross-Validation Running Average F1-Score')\n",
    "# plt.show()\n",
    "# plot_confusion_matrix(sum(rf_nested_conf_matrix),class_labels)\n",
    "\n",
    "# plt.plot(range(1, len(svm_cv_scores) + 1), svm_cv_scores, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('SVM Nested Cross-Validation Running Average Results')\n",
    "# plt.show()\n",
    "# svm_f1_score = [sum(svm_nested_f1_score[:i+1]) / (i+1) for i in range(len(svm_nested_f1_score))]\n",
    "# plt.plot(range(1, len(svm_f1_score) + 1), svm_f1_score, marker='o', linestyle='--')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('SVM Nested Cross-Validation Running Average F1-Score')\n",
    "# plt.show()\n",
    "# plot_confusion_matrix(sum(svm_nested_conf_matrix),class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9936fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_f1_score[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2d626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the control model and compare results to other models\n",
    "\n",
    "# Find the single most important feature\n",
    "# Here, we'll use the absolute correlation between each feature and the target variable as the measure of importance\n",
    "feature_importance = np.abs(np.corrcoef(X_train.T, y_train)[0, 1:])\n",
    "most_important_feature_index = np.argmax(feature_importance)\n",
    "y_pred = np.zeros(len(X_test))\n",
    "\n",
    "# Train the control model\n",
    "# The model will simply predict the class based on the value of the most important feature\n",
    "if two_class:\n",
    "    threshold = np.median(X_train[:, most_important_feature_index])\n",
    "    y_pred[X_test[:, most_important_feature_index] > threshold] = 0\n",
    "    y_pred[X_test[:, most_important_feature_index] <= threshold] = 1\n",
    "\n",
    "if three_class:\n",
    "    # Find the thresholds for separating the three classes\n",
    "    threshold1 = np.percentile(X_train[:, most_important_feature_index], 33)\n",
    "    threshold2 = np.percentile(X_train[:, most_important_feature_index], 67)\n",
    "    y_pred[X_test[:, most_important_feature_index] <= threshold1] = 0\n",
    "    y_pred[(X_test[:, most_important_feature_index] > threshold1) & (X_test[:, most_important_feature_index] <= threshold2)] = 1\n",
    "    y_pred[X_test[:, most_important_feature_index] > threshold2] = 2\n",
    "\n",
    "y_pred_majority = np.ones(len(X_test))\n",
    "f1_majority = f1_score(y_test, y_pred_majority, average='weighted')\n",
    "\n",
    "models = {\n",
    "    'Control Model': y_pred,\n",
    "    'KNN': best_knn_model_overall,\n",
    "    'Random Forest': best_rf_model_overall,\n",
    "    'SVM': best_svm_model_overall\n",
    "}\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Control Model':\n",
    "        y_pred = model\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(np.array(conf_matrix),class_labels)\n",
    "\n",
    "    # Calculate Sensitivity and Specificity\n",
    "    sensitivity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    specificity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Sensitivity: {sensitivity}\")\n",
    "    print(f\"{model_name} Specificity: {specificity}\")\n",
    "    print(f\"{model_name} F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "    f1_scores.append((model_name, f1))\n",
    "\n",
    "# Sort models by F1 score\n",
    "f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Move the control model to the left\n",
    "control_model = f1_scores.pop()\n",
    "f1_scores.insert(0, control_model)\n",
    "\n",
    "# Create bar plot\n",
    "labels, scores = zip(*f1_scores)\n",
    "plt.bar(labels, scores)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('F1-Score Comparison of Models on Test Set')\n",
    "plt.xticks(fontsize=10)\n",
    "plt.axhline(y=f1_majority, color='red', linestyle='dotted', label='Predict Majority Class for All')\n",
    "plt.legend()\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f042c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "\n",
    "control_f1s = []\n",
    "# Train the control model and compare results to other models\n",
    "for i in range(num_bootstrap_iterations):\n",
    "    # Resample the data with replacement to form a new dataset\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, random_state=i)\n",
    "    # Find the single most important feature\n",
    "    # Here, we'll use the absolute correlation between each feature and the target variable as the measure of importance\n",
    "    feature_importance = np.abs(np.corrcoef(X_resampled.T, y_resampled)[0, 1:])\n",
    "    most_important_feature_index = np.argmax(feature_importance)\n",
    "    y_pred = np.zeros(len(X_test))\n",
    "\n",
    "    # Train the control model\n",
    "    # The model will simply predict the class based on the value of the most important feature\n",
    "    if two_class:\n",
    "        threshold = np.median(X_resampled[:, most_important_feature_index])\n",
    "        y_pred[X_test[:, most_important_feature_index] > threshold] = 0\n",
    "        y_pred[X_test[:, most_important_feature_index] <= threshold] = 1\n",
    "\n",
    "    if three_class:\n",
    "        # Find the thresholds for separating the three classes\n",
    "        threshold1 = np.percentile(X_resampled[:, most_important_feature_index], 33)\n",
    "        threshold2 = np.percentile(X_resampled[:, most_important_feature_index], 67)\n",
    "        y_pred[X_test[:, most_important_feature_index] <= threshold1] = 0\n",
    "        y_pred[(X_test[:, most_important_feature_index] > threshold1) & (X_test[:, most_important_feature_index] <= threshold2)] = 1\n",
    "        y_pred[X_test[:, most_important_feature_index] > threshold2] = 2\n",
    "\n",
    "    models = {\n",
    "        'Control Model': y_pred,\n",
    "        'KNN': best_knn_model_overall,\n",
    "        'Random Forest': best_rf_model_overall,\n",
    "        'SVM': best_svm_model_overall\n",
    "    }\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calculate Sensitivity and Specificity\n",
    "    sensitivity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    specificity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    control_f1s.append(f1)\n",
    "\n",
    "control_CI = compute_CI(control_f1s)\n",
    "rf_CI = compute_CI(rf_bootstrap_f1_score)\n",
    "knn_CI = compute_CI(knn_bootstrap_f1_score)\n",
    "svm_CI = compute_CI(svm_bootstrap_f1_score)  \n",
    "    \n",
    "f1_scores.append(('Control Model', np.mean(control_f1s), control_CI))\n",
    "f1_scores.append(('RF', np.mean(rf_bootstrap_f1_score), rf_CI))\n",
    "f1_scores.append(('KNN', np.mean(knn_bootstrap_f1_score), knn_CI))\n",
    "f1_scores.append(('SVM', np.mean(svm_bootstrap_f1_score), svm_CI))\n",
    "\n",
    "y_pred_majority = np.ones(len(X_test))\n",
    "f1_majority = f1_score(y_test, y_pred_majority, average='weighted')\n",
    "\n",
    "# Move the control model to the left\n",
    "# control_model = f1_scores.pop()\n",
    "# f1_scores.insert(0, control_model)\n",
    "\n",
    "# Sort models by F1 score\n",
    "# f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create bar plot\n",
    "labels, scores, CIs = zip(*f1_scores)\n",
    "lower_bounds, upper_bounds = zip(*CIs)\n",
    "# Calculate error bars\n",
    "y_err_lower = [score - lb for score, lb in zip(scores, lower_bounds)]\n",
    "y_err_upper = [ub - score for score, ub in zip(scores, upper_bounds)]\n",
    "plt.bar(labels, scores, yerr=[y_err_lower, y_err_upper], capsize=5, color='skyblue', ecolor='black')\n",
    "plt.xlabel('Model', fontsize=14)\n",
    "plt.ylabel('F1-Score', fontsize=14)\n",
    "plt.title('F1-Score Comparison of Models on Test Set', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=f1_majority, color='red', linestyle='dotted', label='Predict Majority Class for All')\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylim([0,1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class boundaries using PCA\n",
    "if use_PCA:\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    markers = ['s', 'x', 'o']\n",
    "    for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "        if three_class:\n",
    "            if l == 0:\n",
    "                grade = 'Grade I'\n",
    "            elif l == 1:\n",
    "                grade = 'Grade II'\n",
    "            else:\n",
    "                grade = 'Grade III'\n",
    "        elif two_class:\n",
    "            if l == 0:\n",
    "                grade = 'Grade I'\n",
    "            elif l == 1:\n",
    "                grade = 'Grade II/III'\n",
    "        plt.scatter(X_train[y_train == l, 0], X_train[y_train == l, 1], c=c, label=grade, marker=m)\n",
    "\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Low-dimensional Visualization of Class Boundaries using PCA in Train Data')\n",
    "    plt.show()\n",
    "\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    markers = ['s', 'x', 'o']\n",
    "    for l, c, m in zip(np.unique(y_test), colors, markers):\n",
    "        if three_class:\n",
    "            if l == 0:\n",
    "                grade = 'Grade I'\n",
    "            elif l == 1:\n",
    "                grade = 'Grade II'\n",
    "            else:\n",
    "                grade = 'Grade III'\n",
    "        elif two_class:\n",
    "            if l == 0:\n",
    "                grade = 'Grade I'\n",
    "            elif l == 1:\n",
    "                grade = 'Grade II/III'\n",
    "        plt.scatter(X_test[y_test == l, 0], X_test[y_test == l, 1], c=c, label=grade, marker=m)\n",
    "\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Low-dimensional Visualization of Class Boundaries using PCA in Test Data')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ea1c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "if use_PCA and number_of_PCA_components == 2:\n",
    "    models = {\n",
    "        'KNN': knn_model,\n",
    "        'Random Forest': rf_model,\n",
    "        'SVM': svm_model,\n",
    "        'Logistic Regression': lr_model\n",
    "    }\n",
    "\n",
    "    # Create a mesh grid for plotting decision boundaries\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    # Create a 3x1 grid of subplots\n",
    "    fig, axarr = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axarr = axarr.flatten()\n",
    "    \n",
    "    colors = np.array(['blue', 'red'])\n",
    "    markers = np.array(['s', 'x'])\n",
    "\n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        if name == 'Logistic Regression':\n",
    "            y_logit = model(torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)).detach().numpy()\n",
    "            y_prob = 1 / (1 + np.exp(-y_logit))\n",
    "            y_pred = np.where(y_prob[:, 0] > 0.5, 1, 0)\n",
    "            Z = y_pred.reshape(xx.shape)\n",
    "        else:\n",
    "            # Fit the model and predict on the mesh grid\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot the decision boundaries\n",
    "        axarr[idx].contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "        for i in range(len(X_test.tolist())):\n",
    "            axarr[idx].scatter(X_test[i, 0], X_test[i, 1], c=colors[y_test.astype(int)][i], marker=markers[y_test.astype(int)][i])\n",
    "        axarr[idx].set_xlabel('Feature 1')\n",
    "        axarr[idx].set_ylabel('Feature 2')\n",
    "        axarr[idx].set_title(name)\n",
    "\n",
    "    # Add the legend\n",
    "    legend_elements = [Line2D([0], [0], marker='s', color='w', label='Grade I', markerfacecolor='blue', markersize=10),\n",
    "                       Line2D([0], [0], marker='x', color='w', label='Grade II/III', markerfacecolor='red', markersize=10)]\n",
    "    plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to format the table\n",
    "def render_mpl_table(data, col_width=3, row_height=0.625, font_size=12,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0, ax=None, table_title=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in mpl_table._cells.items():\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "            cell.get_text().set(ha='center') # Align header text to center\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0] % len(row_colors)])\n",
    "            cell.get_text().set(ha='center')  # Align cell text to center\n",
    "            value = cell.get_text().get_text()\n",
    "            if '.' in value:\n",
    "                try:\n",
    "                    float_val = float(value)\n",
    "                    if float_val.is_integer():\n",
    "                        cell.get_text().set_text(f'{int(float_val)}')\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    \n",
    "    # Add table title if provided\n",
    "    if table_title:\n",
    "        ax.annotate(table_title, xy=(0.5, 1.15), xycoords='axes fraction',\n",
    "                    fontsize=font_size + 2, ha='center', va='center')\n",
    "        \n",
    "    return ax\n",
    "\n",
    "def plot_kaplan_meier_and_at_risk_table(df,title):\n",
    "    # Fit Kaplan-Meier curves for each group\n",
    "    kmf_A = KaplanMeierFitter()\n",
    "    kmf_B = KaplanMeierFitter()\n",
    "\n",
    "    group_A = df[df['group'] == 0]\n",
    "    group_B = df[df['group'] == 1]\n",
    "\n",
    "    kmf_A.fit(group_A['time'], group_A['event'], label='RF Predicted Grade I')\n",
    "    kmf_B.fit(group_B['time'], group_B['event'], label='RF Predicted Grade II/III')\n",
    "\n",
    "    # Perform log-rank test\n",
    "    results = logrank_test(group_A['time'], group_B['time'], event_observed_A=group_A['event'], event_observed_B=group_B['event'])\n",
    "    log_rank_p_value = results.p_value\n",
    "    test_statistic = results.test_statistic\n",
    "\n",
    "    # Set font style\n",
    "    font = {'family': 'serif',\n",
    "            'weight': 'normal',\n",
    "            'size': 14}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # Create plot with better formatting and styling\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    kmf_A.plot(ax=ax, linewidth=2)\n",
    "    kmf_B.plot(ax=ax, linewidth=2)\n",
    "\n",
    "    # Add log-rank test results and other metrics to the plot\n",
    "    ax.annotate(f'Log-rank test\\np-value: {log_rank_p_value:.3f}\\nTest statistic: {test_statistic:.3f}', \n",
    "                xy=(0.6, 0.2), xycoords='axes fraction', fontsize=12, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
    "\n",
    "    ax.set_xlabel('Time (Months)', fontsize=16)\n",
    "    ax.set_ylabel('Survival Probability', fontsize=16)\n",
    "    ax.set_title(title, fontsize=18, pad=20)\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "    # Customize the grid\n",
    "    ax.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.6)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Remove the top and right spines for a cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Define time points for the number at risk table\n",
    "    time_points = np.arange(0, df['time'].max(), 12)  # Every 12 months\n",
    "\n",
    "    # Calculate the number at risk for each group at the defined time points\n",
    "    number_at_risk_A = kmf_A.event_table.reindex(time_points, method='ffill')['at_risk'].values\n",
    "    number_at_risk_B = kmf_B.event_table.reindex(time_points, method='ffill')['at_risk'].values\n",
    "\n",
    "    # Create the table with the number at risk for each group at the defined time points\n",
    "    at_risk_table = pd.DataFrame({'Time (Months)': time_points,\n",
    "                                  'RF Predicted Grade I': number_at_risk_A,\n",
    "                                  'RF Predicted Grade II/III': number_at_risk_B})\n",
    "\n",
    "\n",
    "\n",
    "    # Add the table to the plot\n",
    "    render_mpl_table(at_risk_table.round(1), header_columns=0, col_width=3.5, table_title='Number at Risk')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c06a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Progression Free Survival and Overall Survival Curves\n",
    "\n",
    "# Get the patient IDs in the test set\n",
    "# Find the corresponding PFS and OS for each of the patients in the test set (make a new variables y_pfs and y_os to track this)\n",
    "# Plot the Kaplan Meier curves for predicted Grade I vs predicted Grade II/III\n",
    "\n",
    "df_y_survival = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_patient.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "# Get the Overall Survival (Months) for the patients in X_test\n",
    "y_time_os = df_y_survival.loc[(patient_ids_test, slice(None)), \"Overall Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_os = df_y_survival.loc[(patient_ids_test, slice(None)), \"Overall Survival Status\"].reset_index(level=1, drop=True)\n",
    "y_time_pfs = df_y_survival.loc[(patient_ids_test, slice(None)), \"Progress Free Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_pfs = df_y_survival.loc[(patient_ids_test, slice(None)), \"Progression Free Status\"].reset_index(level=1, drop=True)\n",
    "\n",
    "# Set survival status and progression free status to 0 or 1 and convert times from strings to floats\n",
    "y_time_os = y_time_os.astype(float)\n",
    "y_status_os = y_status_os.replace({\"0:LIVING\": 0, \"1:DECEASED\": 1})\n",
    "y_time_pfs = y_time_pfs.astype(float)\n",
    "y_status_pfs = y_status_pfs.replace({\"0:CENSORED\": 0, \"1:PROGRESSION\": 1})\n",
    "\n",
    "y_pred = best_rf_model_overall.predict(X_test)\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = {'time': y_time_os,\n",
    "        'event': y_status_os,\n",
    "        'group': y_pred}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plot_kaplan_meier_and_at_risk_table(df,'Kaplan-Meier Curves with Log-rank Test Results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0651863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Progression Free Survival and Overall Survival Curves\n",
    "\n",
    "# Get the patient IDs in the test set\n",
    "# Find the corresponding PFS and OS for each of the patients in the test set (make a new variables y_pfs and y_os to track this)\n",
    "# Plot the Kaplan Meier curves for predicted Grade I vs predicted Grade II/III\n",
    "\n",
    "df_y_survival = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_patient.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "# Get the Overall Survival (Months) for the patients in X_test\n",
    "y_time_os = df_y_survival.loc[(patient_ids_test, slice(None)), \"Overall Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_os = df_y_survival.loc[(patient_ids_test, slice(None)), \"Overall Survival Status\"].reset_index(level=1, drop=True)\n",
    "y_time_pfs = df_y_survival.loc[(patient_ids_test, slice(None)), \"Progress Free Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_pfs = df_y_survival.loc[(patient_ids_test, slice(None)), \"Progression Free Status\"].reset_index(level=1, drop=True)\n",
    "\n",
    "# Set survival status and progression free status to 0 or 1 and convert times from strings to floats\n",
    "y_time_os = y_time_os.astype(float)\n",
    "y_status_os = y_status_os.replace({\"0:LIVING\": 0, \"1:DECEASED\": 1})\n",
    "y_time_pfs = y_time_pfs.astype(float)\n",
    "y_status_pfs = y_status_pfs.replace({\"0:CENSORED\": 0, \"1:PROGRESSION\": 1})\n",
    "\n",
    "y_pred = y_test\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = {'time': y_time_os,\n",
    "        'event': y_status_os,\n",
    "        'group': y_pred}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plot_kaplan_meier_and_at_risk_table(df,'Kaplan-Meier Curves with Log-rank Test Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f59649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Progression Free Survival and Overall Survival Curves\n",
    "\n",
    "'''\n",
    "First, regenerate just train dataset without SMOTE, which may have been used above\n",
    "SMOTE adds new synthetic data that we don't want to include in our survival curve analysis\n",
    "'''\n",
    "\n",
    "'''\n",
    "Load in the data\n",
    "'''\n",
    "\n",
    "X_train=X_train_no_SMOTE\n",
    "y_train=y_train_no_SMOTE\n",
    "\n",
    "\n",
    "# Get the patient IDs in the TRAIN SET (this is not a good estimate of the model performance, rather it estimates the predictiveness of grade for survival)\n",
    "# Find the corresponding PFS and OS for each of the patients in the test set (make a new variables y_pfs and y_os to track this)\n",
    "# Plot the Kaplan Meier curves for predicted Grade I vs predicted Grade II/III\n",
    "\n",
    "df_y_survival = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_patient.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "patient_ids=patient_ids_train\n",
    "# Get the Overall Survival (Months) for the patients in X_test\n",
    "y_time_os = df_y_survival.loc[(patient_ids, slice(None)), \"Overall Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_os = df_y_survival.loc[(patient_ids, slice(None)), \"Overall Survival Status\"].reset_index(level=1, drop=True)\n",
    "y_time_pfs = df_y_survival.loc[(patient_ids, slice(None)), \"Progress Free Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_pfs = df_y_survival.loc[(patient_ids, slice(None)), \"Progression Free Status\"].reset_index(level=1, drop=True)\n",
    "\n",
    "# Set survival status and progression free status to 0 or 1 and convert times from strings to floats\n",
    "y_time_os = y_time_os.astype(float)\n",
    "y_status_os = y_status_os.replace({\"0:LIVING\": 0, \"1:DECEASED\": 1})\n",
    "y_time_pfs = y_time_pfs.astype(float)\n",
    "y_status_pfs = y_status_pfs.replace({\"0:CENSORED\": 0, \"1:PROGRESSION\": 1})\n",
    "\n",
    "y_train_pred = best_rf_model_overall.predict(X_train)\n",
    "\n",
    "# Sample data\n",
    "data = {'time': y_time_os,\n",
    "        'event': y_status_os,\n",
    "        'group': y_train_pred}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plot_kaplan_meier_and_at_risk_table(dfm,'Kaplan-Meier Curves with Log-rank Train Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Progression Free Survival and Overall Survival Curves\n",
    "\n",
    "'''\n",
    "First, regenerate just train dataset without SMOTE, which may have been used above\n",
    "SMOTE adds new synthetic data that we don't want to include in our survival curve analysis\n",
    "'''\n",
    "\n",
    "'''\n",
    "Load in the data\n",
    "'''\n",
    "\n",
    "X_train=X_train_no_SMOTE\n",
    "y_train=y_train_no_SMOTE\n",
    "\n",
    "\n",
    "# Get the patient IDs in the TRAIN SET (this is not a good estimate of the model performance, rather it estimates the predictiveness of grade for survival)\n",
    "# Find the corresponding PFS and OS for each of the patients in the test set (make a new variables y_pfs and y_os to track this)\n",
    "# Plot the Kaplan Meier curves for predicted Grade I vs predicted Grade II/III\n",
    "\n",
    "df_y_survival = pd.read_csv(\"paad_tcga_pan_can_atlas_2018/data_clinical_patient.txt\", sep='\\t', index_col=[0, 1])\n",
    "\n",
    "patient_ids=patient_ids_train\n",
    "# Get the Overall Survival (Months) for the patients in X_test\n",
    "y_time_os = df_y_survival.loc[(patient_ids, slice(None)), \"Overall Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_os = df_y_survival.loc[(patient_ids, slice(None)), \"Overall Survival Status\"].reset_index(level=1, drop=True)\n",
    "y_time_pfs = df_y_survival.loc[(patient_ids, slice(None)), \"Progress Free Survival (Months)\"].reset_index(level=1, drop=True)\n",
    "y_status_pfs = df_y_survival.loc[(patient_ids, slice(None)), \"Progression Free Status\"].reset_index(level=1, drop=True)\n",
    "\n",
    "# Set survival status and progression free status to 0 or 1 and convert times from strings to floats\n",
    "y_time_os = y_time_os.astype(float)\n",
    "y_status_os = y_status_os.replace({\"0:LIVING\": 0, \"1:DECEASED\": 1})\n",
    "y_time_pfs = y_time_pfs.astype(float)\n",
    "y_status_pfs = y_status_pfs.replace({\"0:CENSORED\": 0, \"1:PROGRESSION\": 1})\n",
    "\n",
    "# y_train_pred = rf_model.predict(X_train)\n",
    "y_train_pred = y_train\n",
    "\n",
    "# Sample data\n",
    "data = {'time': y_time_os,\n",
    "        'event': y_status_os,\n",
    "        'group': y_train_pred}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plot_kaplan_meier_and_at_risk_table(df,'Kaplan-Meier Curves with Log-rank Train Labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff87433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zambir",
   "language": "python",
   "name": "zambir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
